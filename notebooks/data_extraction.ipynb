{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Library imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pandas for creating dataframes\n",
    "import pandas as pd\n",
    "\n",
    "#Pyshark to capture packets\n",
    "import pyshark\n",
    "#For file operarions\n",
    "import os\n",
    "import gc\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define required attributed needed to extract from capture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "required_keys = ['ip.dst', 'ip.proto', 'tcp.flags.syn', 'tcp.flags.ack']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading packets from pre-captured file using Pyshark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_cap = pyshark.FileCapture('captures/botnet-capture-20110810-neris.pcap')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraxt IP packets from the captured file for further processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "1 1312966900.475792 1312967200.475792\n",
      "2 1312967200.475792 1312967500.475792\n",
      "3 1312967500.475792 1312967800.475792\n",
      "4 1312967800.475792 1312968100.475792\n",
      "5 1312968100.475792 1312968400.475792\n",
      "6 1312968400.475792 1312968700.475792\n",
      "7 1312968700.475792 1312969000.475792\n",
      "8 1312969000.475792 1312969300.475792\n",
      "9 1312969300.475792 1312969600.475792\n",
      "10 1312969600.475792 1312969900.475792\n",
      "11 1312969900.475792 1312970200.475792\n",
      "12 1312970200.475792 1312970500.475792\n",
      "13 1312970500.475792 1312970800.475792\n",
      "14 1312970800.475792 1312971100.475792\n",
      "15 1312971100.475792 1312971400.475792\n",
      "16 1312971400.475792 1312971700.475792\n",
      "17 1312971700.475792 1312972000.475792\n",
      "18 1312972000.475792 1312972300.475792\n",
      "19 1312972300.475792 1312972600.475792\n",
      "20 1312972600.475792 1312972900.475792\n",
      "21 1312972900.475792 1312973200.475792\n",
      "22 1312973200.475792 1312973500.475792\n",
      "23 1312973500.475792 1312973800.475792\n",
      "24 1312973800.475792 1312974100.475792\n",
      "25 1312974100.475792 1312974400.475792\n",
      "26 1312974400.475792 1312974700.475792\n",
      "27 1312974700.475792 1312975000.475792\n",
      "28 1312975000.475792 1312975300.475792\n",
      "29 1312975300.475792 1312975600.475792\n",
      "30 1312975600.475792 1312975900.475792\n",
      "31 1312975900.475792 1312976200.475792\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "#Write extraction result to\n",
    "base_directory = 'converted/test3/attack_samples/1/'\n",
    "#Debugger for pyshark\n",
    "#file_cap.set_debug()\n",
    "#Attributes for sample size\n",
    "startTime = 0.0\n",
    "endTime = 0.0\n",
    "i = -1\n",
    "first = True\n",
    "#Sample Number\n",
    "init_sample = 1\n",
    "dfList = []\n",
    "while(True):\n",
    "    i += 1\n",
    "    #Each packet can have multiple layers (e.g eth, ip, tcp etc.). \n",
    "    #Combine them in list for a single packet.\n",
    "    layerList = []\n",
    "    #pyshark not able to handle AttributeError, AssertionError and KeyError(index values)\n",
    "    try:\n",
    "        #Iterate through layer of packet\n",
    "        for layer in file_cap[i]:\n",
    "            # Slice Data according to time\n",
    "            t = float(file_cap[i].sniff_timestamp)\n",
    "            #Initial setup\n",
    "            if startTime == 0.0:\n",
    "                startTime = t\n",
    "                endTime = startTime + 300 # 300 sec(5 min) is the sample size\n",
    "                sample = init_sample\n",
    "                print(sample, startTime, endTime)\n",
    "            # Write every sample to csv file\n",
    "            elif t > endTime:\n",
    "                if not os.path.exists(base_directory):\n",
    "                    os.makedirs(base_directory)\n",
    "                dfList.to_csv(base_directory+str(sample))\n",
    "                #Clear list after writing this would save memory\n",
    "                startTime = endTime\n",
    "                endTime = startTime + 300\n",
    "                sample += 1\n",
    "                #Reset after writing to file\n",
    "                first = True\n",
    "                print(sample, startTime, endTime)\n",
    "                gc.collect()\n",
    "            #We need only ip layer only\n",
    "            if layer._layer_name == 'ip':\n",
    "                #Layer values are in the form of dictionary. Filter the attributes\n",
    "                layer_dict = {key:value for key, value in layer._all_fields.items() \n",
    "                              if key in required_keys}\n",
    "                #Create dataframe from dictionary\n",
    "                layerList.append(pd.DataFrame(layer_dict, index=[0]))\n",
    "                #Add timestamp and sample number\n",
    "                layerList.append(pd.DataFrame({'sniff_timestamp':file_cap[i].sniff_timestamp}, \n",
    "                                              index=[0]))\n",
    "                layerList.append(pd.DataFrame({'sample':sample}, index=[0]))\n",
    "                #Build packet dataframe from layer frames. Its single row dataframe\n",
    "                cDf = pd.concat(layerList, axis=1);\n",
    "                if first:\n",
    "                    dfList = cDf\n",
    "                    first = False\n",
    "                else:\n",
    "                    dfList = dfList.append(cDf, ignore_index=True)\n",
    "    except (AttributeError, AssertionError) as e:\n",
    "        continue  #print('Ipv4 packet does not exist')\n",
    "    except  KeyError:\n",
    "        break;\n",
    "\n",
    "#If sample data is not written to file because for frame size\n",
    "if(sample == init_sample):\n",
    "    dfList.to_csv(base_directory+str(init_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py36]",
   "language": "python",
   "name": "Python [py36]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
